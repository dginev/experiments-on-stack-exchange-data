{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook was written while **learning** about:\n",
    "1. the seq2seq implementations using \"teacher forcing\" in Keras.\n",
    "2. using DistilBert via huggingface's transformers. \n",
    "3. using `tf.data` and tensorflow 2 for high performance data pipelines\n",
    "\n",
    "As such, please treat it as a scratch book of a student more than a tutorial. Ideally only use it for brainstorming, rather than relying on any particular part. It is quite possible that the model design here has hidden \"gotchas\" or outright glaring mistakes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from transformers import DistilBertTokenizerFast, TFDistilBertModel, DistilBertConfig\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from pathlib import Path\n",
    "data_path = Path('../data') / 'span_model_oie'\n",
    "model_path = Path('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data sizes: x_train (10000, 128), y_train (10000, 64), x_test (2500, 128), y_test (2500, 64) .\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path('../data') / 'span_model_oie'\n",
    "path_hdf5 = str(data_path/'encoded_sample.hdf5')\n",
    "# Let's quickly get the shapes from HDF5 for bookkeeping\n",
    "if 'fp' in locals():\n",
    "    fp.close()\n",
    "fp = h5py.File(data_path / \"encoded_sample.hdf5\", \"r\")\n",
    "x_train = fp['x_train']\n",
    "x_test = fp['x_test']\n",
    "y_train = fp['y_train']\n",
    "y_test = fp['y_test']\n",
    "x_train_shape = x_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "x_test_shape = x_test.shape\n",
    "y_test_shape = y_test.shape\n",
    "fp.close()\n",
    "print(\"data sizes: x_train %s, y_train %s, x_test %s, y_test %s .\" % \\\n",
    "      (x_train_shape, y_train_shape, x_test_shape, y_test_shape))\n",
    "validation_index = 1+int(0.9*x_train_shape[0])\n",
    "\n",
    "x_test = tfio.IODataset.from_hdf5(path_hdf5, dataset='/x_test')\n",
    "y_test = tfio.IODataset.from_hdf5(path_hdf5, dataset='/y_test')\n",
    "x_train = tfio.IODataset.from_hdf5(path_hdf5, dataset='/x_train')\n",
    "y_train = tfio.IODataset.from_hdf5(path_hdf5, dataset='/y_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'activation_13', 'vocab_projector', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Thanks to the excellent tutorial at:\n",
    "# https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
    "# Setup the config and embedding layer, then prep data.\n",
    "distil_bert = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(distil_bert)\n",
    "max_input_size = 128\n",
    "max_target_size = 64\n",
    "\n",
    "config = DistilBertConfig(dropout=0.2, attention_dropout=0.2, trainable=False)\n",
    "config.output_hidden_states = False\n",
    "transformer_model = TFDistilBertModel.from_pretrained(distil_bert, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_1 (TFDisti ((None, 128, 768),)  66362880    input_token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 30522) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 128), (None, 459264      tf_distil_bert_model_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 128),  15693312    input_2[0][0]                    \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 30522)  3937338     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 86,452,794\n",
      "Trainable params: 20,089,914\n",
      "Non-trainable params: 66,362,880\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the full model.\n",
    "# The crucial part for our setup is \"teacher forcing\", so as to properly teach the full triple generation\n",
    "# Great starting example at: https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py#L159\n",
    "vocab_size = tokenizer.vocab_size\n",
    "num_encoder_tokens = num_decoder_tokens = vocab_size\n",
    "latent_dim = int(max_input_size)\n",
    "\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(max_input_size,), name='input_token', dtype='int32')\n",
    "encoder_masks  = tf.keras.layers.Input(shape=(max_input_size,), name='masked_token', dtype='int32')\n",
    "\n",
    "lm_embedding = transformer_model(encoder_inputs, attention_mask=encoder_masks)[0]\n",
    "encoder = tf.keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(lm_embedding)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                      initial_state=encoder_states)\n",
    "decoder_dense = tf.keras.layers.Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = tf.keras.Model([encoder_inputs, encoder_masks, decoder_inputs], decoder_outputs)\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "  layer.trainable = False\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data stream and iterate efficiently via tf.data\n",
    "label_dim = tokenizer.vocab_size\n",
    "batch_size = 80\n",
    "\n",
    "full_train_hdf5 =  tf.data.Dataset.zip((x_train,y_train))\n",
    "\n",
    "# we need to map the HDF5 x,y into ((x, x_mask, y_teacher), y_target)\n",
    "# where \n",
    "# 1) x_mask is an attention mask that simply zeros-out padding tokens and enables all regular tokens\n",
    "# 2) we are doing \"teacher forcing\" with a y_teacher and a shift-by-1 y_target\n",
    "full_train = full_train_hdf5.map(\\\n",
    "    lambda x,y:((x,tf.cast(tf.math.not_equal(x, 0), tf.int64),\\\n",
    "                 tf.one_hot(y,label_dim)),\\\n",
    "                 tf.one_hot(tf.concat([tf.slice(y, [1], [max_target_size-1]), [0]],0),label_dim)))\n",
    "\n",
    "# we can now split out a validation set and batch the datasets\n",
    "train_batched = full_train.take(validation_index).batch(batch_size)\n",
    "validation_batched = full_train.skip(validation_index).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "    113/Unknown - 111s 980ms/step - loss: 1.1698 - accuracy: 0.8443WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 1.1698 - accuracy: 0.8443 - val_loss: 1.3820 - val_accuracy: 0.8302\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0864 - accuracy: 0.8518WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 124s 1s/step - loss: 1.0864 - accuracy: 0.8518 - val_loss: 1.3534 - val_accuracy: 0.8306\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0315 - accuracy: 0.8585WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 125s 1s/step - loss: 1.0315 - accuracy: 0.8585 - val_loss: 1.2926 - val_accuracy: 0.8437\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9864 - accuracy: 0.8645WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.9864 - accuracy: 0.8645 - val_loss: 1.2636 - val_accuracy: 0.8455\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9468 - accuracy: 0.8679WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.9468 - accuracy: 0.8679 - val_loss: 1.2313 - val_accuracy: 0.8460\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9094 - accuracy: 0.8723WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 127s 1s/step - loss: 0.9094 - accuracy: 0.8723 - val_loss: 1.2029 - val_accuracy: 0.8481\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8758 - accuracy: 0.8755WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 128s 1s/step - loss: 0.8758 - accuracy: 0.8755 - val_loss: 1.1773 - val_accuracy: 0.8500\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8477 - accuracy: 0.8786WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 127s 1s/step - loss: 0.8477 - accuracy: 0.8786 - val_loss: 1.1675 - val_accuracy: 0.8512\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8221 - accuracy: 0.8814WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.8221 - accuracy: 0.8814 - val_loss: 1.1480 - val_accuracy: 0.8517\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7982 - accuracy: 0.8837WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.7982 - accuracy: 0.8837 - val_loss: 1.1272 - val_accuracy: 0.8532\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7769 - accuracy: 0.8859WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.7769 - accuracy: 0.8859 - val_loss: 1.1137 - val_accuracy: 0.8534\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7571 - accuracy: 0.8878WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.7571 - accuracy: 0.8878 - val_loss: 1.1073 - val_accuracy: 0.8554\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7392 - accuracy: 0.8897WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.7392 - accuracy: 0.8897 - val_loss: 1.0916 - val_accuracy: 0.8568\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7222 - accuracy: 0.8920WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.7222 - accuracy: 0.8920 - val_loss: 1.0873 - val_accuracy: 0.8586\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7070 - accuracy: 0.8938WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 127s 1s/step - loss: 0.7070 - accuracy: 0.8938 - val_loss: 1.0784 - val_accuracy: 0.8606\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.8957WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 127s 1s/step - loss: 0.6917 - accuracy: 0.8957 - val_loss: 1.0745 - val_accuracy: 0.8618\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.8968WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.6780 - accuracy: 0.8968 - val_loss: 1.0642 - val_accuracy: 0.8665\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6648 - accuracy: 0.8977WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.6648 - accuracy: 0.8977 - val_loss: 1.0579 - val_accuracy: 0.8676\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6519 - accuracy: 0.8990WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.6519 - accuracy: 0.8990 - val_loss: 1.0491 - val_accuracy: 0.8695\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.8998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "113/113 [==============================] - 126s 1s/step - loss: 0.6402 - accuracy: 0.8998 - val_loss: 1.0483 - val_accuracy: 0.8708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc6c10d220>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=str(model_path/'checkpoint_sample_oie'),\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "\n",
    "model.fit(train_batched,\n",
    "    validation_data=validation_batched,\n",
    "    workers = 8,\n",
    "    use_multiprocessing=True,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint,earlystop],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(str(model_path / 'sample_oie.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_1 (TFDisti ((None, 128, 768),)  66362880    input_token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 128), (None, 459264      tf_distil_bert_model_1[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 66,822,144\n",
      "Trainable params: 459,264\n",
      "Non-trainable params: 66,362,880\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 30522) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 128),  15693312    input_2[0][0]                    \n",
      "                                                                 input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 30522)  3937338     lstm_3[7][0]                     \n",
      "==================================================================================================\n",
      "Total params: 19,630,650\n",
      "Trainable params: 19,630,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = tf.keras.Model([encoder_inputs,encoder_masks], encoder_states)\n",
    "print(encoder_model.summary())\n",
    "\n",
    "lm_embedding = transformer_model(encoder_inputs, attention_mask=encoder_masks)[0]\n",
    "encoder = tf.keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(lm_embedding)\n",
    "\n",
    "\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = tf.keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "print(decoder_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    input_mask = np.array([0 if x==0 else 1 for x in input_seq[0]]).reshape(1,128)\n",
    "    states_value = encoder_model.predict((input_seq,input_mask))\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    CLS_id = 101 # tokenizer.encode('[CLS]') to check this\n",
    "    PAD_id = 0 \n",
    "    target_seq[0, 0, CLS_id] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    sentence_ids = []\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq]+states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sentence_ids.append(sampled_token_index)\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_token_index == PAD_id or\n",
    "           len(sentence_ids) > max_target_size):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return tokenizer.decode(sentence_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 21. 6 % is used for growing crops and 13. 9 % is pastures, while 1. 4 % is used for orchards or vine crops and 5. 0 % is used for alpine pastures [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 22. 3 % is used for growing crops and 12. 7 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 24. 1 % is used for growing crops and 15. 5 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 26. 6 % is used for growing crops and 10. 1 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 28. 6 % is used for growing crops and 12. 3 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 28. 8 % is used for growing crops and 5. 8 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 29. 7 % is used for growing crops and 8. 0 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 31. 2 % is used for growing crops and 18. 0 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 32. 0 % is used for growing crops and 5. 7 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 35. 8 % is used for growing crops and 6. 4 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 35. 9 % is used for growing crops and 26. 4 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 36. 3 % is used for growing crops and 6. 7 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 37. 6 % is used for growing crops and 13. 3 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 40. 4 % is used for growing crops and 9. 5 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 40. 6 % is used for growing crops and 29. 7 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 40. 7 % is used for growing crops and 6. 3 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 41. 1 % is used for growing crops and 14. 6 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 42. 0 % is used for growing crops and 8. 9 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 42. 2 % is used for growing crops and 28. 7 % is pasturage, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 42. 3 % is used for growing crops and 15. 3 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 42. 5 % is used for growing crops and 15. 6 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 42. 5 % is used for growing crops and 25. 8 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 44. 9 % is used for growing crops and 14. 9 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 45. 1 % is used for growing crops and 6. 9 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 45. 3 % is used for growing crops and 7. 2 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 47. 9 % is used for growing crops and 21. 0 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 48. 4 % is used for growing crops and 9. 8 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 48. 9 % is used for growing crops and 15. 6 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 51. 5 % is used for growing crops and 19. 1 % is pasturage, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 53. 2 % is used for growing crops and 8. 8 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 53. 3 % is used for growing crops and 20. 7 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 53. 4 % is used for growing crops and 6. 2 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 55. 9 % is used for growing crops and 11. 2 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 56. 5 % is used for growing crops and 6. 5 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 57. 2 % is used for growing crops, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 57. 2 % is used for growing crops and 17. 7 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 57. 2 % is used for growing crops and 6. 0 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 58. 3 % is used for growing crops and 4. 4 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 59. 1 % is used for growing crops and 7. 6 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 6. 1 % is used for growing crops, while 1. 4 % is used for orchards or vine crops and 2. 5 % is used for alpine pastures [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 6. 3 % is used for growing crops, while 1. 4 % is used for orchards or vine crops and 29. 2 % is used for alpine pastures [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 61. 8 % is used for growing crops and 13. 2 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 66. 0 % is used for growing crops and 7. 5 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 7. 6 % is used for growing crops, while 1. 4 % is used for orchards or vine crops and 5. 2 % is used for alpine pastures [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 76. 1 % is used for growing crops and 5. 3 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 78. 6 % is used for growing crops and 8. 0 % is pastures, while 1. 4 % is used for orchards or vine crops [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 8. 1 % is used for growing crops, while 1. 4 % is used for orchards or vine crops and 51. 4 % is used for alpine pastures [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the agricultural land, 8. 7 % is used for growing crops and 11. 0 % is pastures, while 1. 4 % is used for orchards or vine crops and 24. 3 % is used for alpine pastures [SEP]\n",
      "\n",
      "Decoded triples: 1. 8 [SEP] is used [SEP] for orchards or vine crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % reported tahitian, and 0. 7 % reported another language [SEP]\n",
      "\n",
      "Decoded triples: the remaining of residents [SEP] spoke [SEP] all other primary languages [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the community was 91. 3 % black, 4. 3 % white, 2. 1 % asian, 1. 4 % reporting more than one race, and. 7 [SEP]\n",
      "\n",
      "Decoded triples: 1. 7 [SEP] were [SEP] of the population [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the first language of 53. 5 % of the population is afrikaans, while 29. 2 % speak xhosa, 12. 3 % speak english and 1. 4 % speak sotho [SEP]\n",
      "\n",
      "Decoded triples: 1. 7 [SEP] speak [SEP] all other primary [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % was in the armed forces, and 67. 9 % was in the civilian labor force with 66. 5 % being employed and 1. 5 % unemployed [SEP]\n",
      "\n",
      "Decoded triples: 10 [SEP] were [SEP] in the primary [SEP]\n",
      "---\n",
      "Input sentence: [CLS] among housing units, 87. 7 % were occupied and 1. 4 % were for seasonal, recreational, or occasional use ; 63. 5 % of occupied housing units were owner - occupied and 36. 5 % were occupied by renters [SEP]\n",
      "\n",
      "Decoded triples: 10. 7 [SEP] were [SEP] to the swiss [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 98. 3 % were from a catholic community background and 1. 4 % were from a ` protestant and other christian background [SEP]\n",
      "\n",
      "Decoded triples: 10 [SEP] were [SEP] had [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % were hispanic or latino of any race [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] were [SEP] hispanic [SEP] of the race [SEP]\n",
      "---\n",
      "Input sentence: [CLS] as of october 2007, 59. 8 % of enrolled students were african american, 24. 4 % were asian, 9. 4 % were hispanic, 5 % were white and 1. 4 % were native american [SEP]\n",
      "\n",
      "Decoded triples: 10. 7 [SEP] were [SEP] of the race [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of the 1, 606 who had completed some form of tertiary schooling listed in the census, 75. 7 % were swiss men, 18. 9 % were swiss women, 4. 0 % were non - swiss men and 1. 4 % were non - swiss women [SEP]\n",
      "\n",
      "Decoded triples: 10. 7 [SEP] were [SEP] non - swiss - - - - - - - - - - - - - - - - - -........... - - - - - - - - - - - litre. 0. 0. 0 [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 5. 6 % of households were unmarried opposite - sex partnerships and 1. 4 % were same - sex married couples or partnerships [SEP]\n",
      "\n",
      "Decoded triples: 10. 7 % of the population [SEP] were [SEP] non [SEP] non or no or present [SEP]\n",
      "---\n",
      "Input sentence: [CLS] at the 2010 census, the township was 91. 9 % non - hispanic white, 1. 4 % black or african american, 0. 9 % asian, and 1. 4 % were two or more races [SEP]\n",
      "\n",
      "Decoded triples: 10. 7 [SEP] were [SEP] of the race [SEP]\n",
      "---\n",
      "Input sentence: [CLS] out of the 30. 7 %, 1. 8 % were sub - saharan africa, 1. 4 % were west indian or afro - caribbean american, and 0. 6 % were black hispanics [SEP]\n",
      "\n",
      "Decoded triples: 10. 7 [SEP] were [SEP] of the race [SEP]\n",
      "---\n",
      "Input sentence: [CLS] one u. s. telephone survey found that 16. 6 % of respondents ` ` picked their skin to the point of noticeable tissue damage'' and that 1. 4 % would qualify as meeting the requirements of excoriation disorder [SEP]\n",
      "\n",
      "Decoded triples: 10. 000 [SEP] were [SEP] to the ` - ` - ` - -.......... - - - - - - - - - - - - - - - - - -tiudeudenznznznz formation shell proposal alpine used used [SEP]\n",
      "---\n",
      "Input sentence: [CLS] in a 2011 study, 1. 4 % of 143 marsh arabs were found to be g, versus 1. 9 % of 154 other iraqis [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] had [SEP] in the population [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of all households had someone living alone who was 65 years of age or older [SEP]\n",
      "\n",
      "Decoded triples: 10 living alone [SEP] was [SEP] 65 years of age or older [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of all households were made up of individuals and none had someone living alone who was 65 years of age or older [SEP]\n",
      "\n",
      "Decoded triples: 10 living alone [SEP] was [SEP] 65 years of age or older [SEP]\n",
      "---\n",
      "Input sentence: [CLS] of this, 1. 4 % of gdp went to funding higher education [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] is [SEP] in the state [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of people reported two or more races [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] were [SEP] 65 or age of age [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of residents hold a college degree, with 17. 7 % continuing education after high school, ranking mecca the 17th least - educated city in the united states [SEP]\n",
      "\n",
      "Decoded triples: 10. 7 [SEP] had [SEP] in the year [SEP]\n",
      "---\n",
      "Input sentence: [CLS] as of 31 march 2013, 1. 4 % of scotland's children were subject to a supervision requirement [SEP]\n",
      "\n",
      "Decoded triples: 10, 000 of the population [SEP] were [SEP] in the 000 [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of the people were of hispanic or latino origin [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] were [SEP] hispanic or latino of any race [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Input sentence: [CLS] as of 2008, 1. 4 % of the population are resident foreign nationals [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] are [SEP] the population of the population [SEP]\n",
      "---\n",
      "Input sentence: [CLS] as of 2012, 1. 4 % of the population are resident foreign nationals [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] are [SEP] the population [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of the population was hispanic or latino of any race [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] were [SEP] hispanic [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of the population was of hispanic or latino ancestry [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] were [SEP] of the population of the population [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of the population were hispanic or latino of any race [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] were [SEP] hispanic [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of the population were indigenous australians [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] were [SEP] are [SEP]\n",
      "---\n",
      "Input sentence: [CLS] 1. 4 % of the population were of hispanic or latino ancestry [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] were [SEP] hispanic or latino of any race [SEP]\n",
      "---\n",
      "Input sentence: [CLS] in addition, 1. 4 % of the students are non - resident international students [SEP]\n",
      "\n",
      "Decoded triples: 10 % of the population [SEP] were [SEP] in the population [SEP]\n",
      "---\n",
      "Input sentence: [CLS] by 2004, annual oil production reached 1. 4 billion barrels producing a net profit of $ 50 billion [SEP]\n",
      "\n",
      "Decoded triples: the million [SEP] was [SEP] in the, 000 million [SEP]\n",
      "---\n",
      "Input sentence: [CLS] national stadium - construction work on the 15, 000 set stadium by top international engineering began in 2010 and ended in 2013, at a cost of 1. 4 billion cape verdean escudos, funded by the chinese government [SEP]\n",
      "\n",
      "Decoded triples: the million [SEP] was [SEP] in the 000 [SEP]\n",
      "---\n",
      "Input sentence: [CLS] with 1. 4 billion lightning flashes per year, multiplied by 7 kilograms per lightning strike, they estimated the total amount of produced by lightning per year is 8. 6 million tonnes [SEP]\n",
      "\n",
      "Decoded triples: 1. 000 million million [SEP] had [SEP] in the 000 [SEP]\n",
      "---\n",
      "Input sentence: [CLS] at the time, ntd control was seen as a monumental task, with 1. 4 billion people infected with and suffering from ntds around the world [SEP]\n",
      "\n",
      "Decoded triples: the million [SEP] was [SEP] in the 000 [SEP]\n",
      "---\n",
      "Input sentence: [CLS] based on the gt200 graphics processor consisting of 1. 4 billion transistors, codenamed tesla, the 200 series was launched on june 16, 2008 [SEP]\n",
      "\n",
      "Decoded triples: the million [SEP] was [SEP] in the - - - - - - - - - - - - - - - - - - - - - - - s - s - s - s - s - s viewers - s. viewers - s. households [SEP] is [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the gt200 is the fifth largest commercial gpu ever constructed, consisting of 1. 4 billion transistors covering a 576 mm2 die surface area built on a 65 nm process [SEP]\n",
      "\n",
      "Decoded triples: the a - - - - - - - - - - - - - - - - - - - - - hour - s - s - s - s - s was was was made [SEP] of a - - - -eeee [SEP]\n",
      "---\n",
      "Input sentence: [CLS] this resulted in a loss of 1. 4 bn kenyan shillings which state organisations had deposited in the bank [SEP]\n",
      "\n",
      "Decoded triples: 10 million 000 million people [SEP] were [SEP] in the [SEP]\n",
      "---\n",
      "Input sentence: [CLS] japan's total fertility rate is 1. 4 children born per woman, which is below the replacement rate of 2. 1 [SEP]\n",
      "\n",
      "Decoded triples: 10 [SEP] born [SEP] in the, 000 rate [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the 1. 3 - litre engine was revised to offer slightly more power, and the 1. 4 d - 4d got a boost to, the former engine allowing it to achieve exceptional fuel economy [SEP]\n",
      "\n",
      "Decoded triples: the the - - - - - - - - - - - - - - - - - - - - - - - - - hour - s consisted - s - s airedee [SEP] was [SEP] in a - - - -eeeee [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the greatest eclipse was in midcentral antarctica at 75. 8 s and 1. 4 e some kilometers from the prime meridian at 16 : 25 utc the duration was 6 min 15 seconds and showed 91. 5 % obscuration of the sun [SEP]\n",
      "\n",
      "Decoded triples: the first [SEP] was [SEP] in the, - -....................... - - - - - - - - - - - - - - -tiudeudenznznznznz franchise alpine proposal alpine used [SEP]\n",
      "---\n",
      "Input sentence: [CLS] maximum film advance speed is 2. 5 frames per second on continuous mode, but can be as slow as 1. 4 frames / s depending on the status of the focus / exposure locks [SEP]\n",
      "\n",
      "Decoded triples: 10 / / / [SEP] is [SEP] a a ` of 10 [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the sz was originally equipped with pirelli p zero tyres and is able to sustain over 1. 1 g in cornering, some drivers have measured a cornering force of 1. 4 g, which remains an excellent performance figure [SEP]\n",
      "\n",
      "Decoded triples: the the ` [SEP] was [SEP] on the 1. 1 [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the kindle 2 features a text - to - speech option to read the text aloud, and 2 gb of internal memory of which 1. 4 gb is user - accessible [SEP]\n",
      "\n",
      "Decoded triples: 10 [SEP] is [SEP] a a ` ` ` ` ` ` ` ` ` [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the gpd xd contains a rockchip rk3288 soc, which consists of an arm cortex - a17 clocked at 1. 4 ghz, paired with the mali - t764, which is clocked at 600 mhz [SEP]\n",
      "\n",
      "Decoded triples: the a - - - - - - - - - - - - - - - - - - - - - - t - s aircraft [SEP] was used [SEP]\n",
      "---\n",
      "Input sentence: [CLS] as early as in 1895, it was known that ammonia was ` ` strongly antiseptic... it requires 1. 4 grams per litre to preserve beef tea [SEP]\n",
      "\n",
      "Decoded triples: 10. 5 [SEP] was [SEP] to the or or or or [SEP]\n",
      "---\n",
      "Input sentence: [CLS] only one bechgaard salt was found to be superconducting at ambient pressure which is 2clo4 with a transition temperature of tc 1. 4 k. several other salts become superconducting only under external pressure [SEP]\n",
      "\n",
      "Decoded triples: 10 - - - - - - - - - - - - - - - - - - s - s - s - s - aired [SEP] was was [SEP] in a - - - -ee [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the tell hagmatana has a circumference of 1. 4 kilometres, which corresponds to a report from polybius, although the ancient greek and roman accounts likely exaggerate ecbatana's wealth, splendor, and extravagance [SEP]\n",
      "\n",
      "Decoded triples: the total [SEP] has [SEP] a the 000 of the.................... - - - - - - - - - -proproproproproproductive land [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the abarth version for north america was introduced in the la auto show in november 2011 with a 1. 4 l turbocharged multiair engine producing and of torque [SEP]\n",
      "\n",
      "Decoded triples: the the - - - - - - - - - - - - - - - - - - - - - - - - - hour - s city was was was [SEP] was [SEP]\n",
      "---\n",
      "Input sentence: [CLS] the four pre - series aircraft were of a short - fuselage design, while the fifth, sixth and seventh prototypes were stretched by 1. 4 m allowing an extra row of passenger seats [SEP]\n",
      "\n",
      "Decoded triples: the the - - - - - - - - - - - - - - - - - - - - - - - - - - consisted consisted - s - s consisted consisted [SEP] was [SEP] of 10 or,, 000 [SEP]\n",
      "---\n",
      "Input sentence: [CLS] in a small chamber, there is a 0. 8 m high and 1. 4 m wide gravestone showing a woman in prayer [SEP]\n",
      "\n",
      "Decoded triples: 1. 5 [SEP] is [SEP] a a of the ` - ` ` ` [SEP]\n",
      "---\n",
      "Input sentence: [CLS] umphenhour bought a piece of land for 1. 4 million dollars, which created the new east cobb baseball facility [SEP]\n",
      "\n",
      "Decoded triples: the km [SEP] was [SEP] in the - - - - - - - - - - - - - - - - - - - building globe crops crops [SEP]\n",
      "---\n",
      "Input sentence: [CLS] examining 1. 4 million guns involved in crime, ` ` in the five - year period before enactment of the federal assault weapons act, assault weapons named in the act constituted 4. 82 % of the crime gun traces atf conducted nationwide [SEP]\n",
      "\n",
      "Decoded triples: 10. 000 [SEP] were [SEP] in the year [SEP]\n",
      "---\n",
      "Input sentence: [CLS] already, key pcia partners have reported helping 1. 4 million households to adopt clean cooking and heating practices, reducing harmful exposures for more than 7. 6 million people [SEP]\n",
      "\n",
      "Decoded triples: 10, 000 children [SEP] born [SEP] to the 000 [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Try to extract triple for first 100 training examples\n",
    "previous = set()\n",
    "for input_seq in iter(x_train):\n",
    "    np_input = np.array(input_seq)\n",
    "    if str(np_input) in previous:\n",
    "        continue\n",
    "    previous.add(str(np_input))\n",
    "    if len(previous)>100:\n",
    "        break\n",
    "    decoded_sentence = decode_sequence(np.array([np_input]))\n",
    "    print('---')\n",
    "    print('Input sentence:', tokenizer.decode(input_seq).replace(' [PAD]',''))\n",
    "    print('')\n",
    "    print('Decoded triples:', decoded_sentence.replace(' [PAD]',''))\n",
    "    #print('Expected triples:', tokenizer.decode(y_train[seq_index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Input: In mathematics, a monomial is, roughly speaking, a polynomial which has only one term.\n",
      "\n",
      "Extracted: 10 the the the [SEP] is [SEP] a a - - - - -....... - - - - - - - - - -propropropronz gymnastics gymnastics gymnastics fife proposal carroll whom whose um um um um um um um um um um um um um um um um um um um um um\n"
     ]
    }
   ],
   "source": [
    "def string_to_triples(text):\n",
    "    text_ids = tokenizer.encode(text, max_length=max_input_size, padding='max_length')\n",
    "    triples = decode_sequence(np.array([text_ids])).replace(' [PAD]','')\n",
    "    print(\"---\")\n",
    "    print(\"Input: %s\"%text)\n",
    "    print(\"\")\n",
    "    print(\"Extracted: %s\"% triples)\n",
    "    \n",
    "    \n",
    "string_to_triples('In mathematics, a monomial is, roughly speaking, a polynomial which has only one term.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "As can be seen from the run above, 20 epochs are already sufficient to overfit 10,000 training examples over 20 million parameters in our training loop. There is nothing to brag about in the decoded triples, generalization is poor if any.\n",
    "\n",
    "It is possible this is also due to the very naive \"teacher forcing\" implementation, which followed closely the seq2seq example from Keras, but without actual expertise, as this is the very first attempt at learning about the seq2seq training setup over such a large vocabulary.\n",
    "\n",
    "Much more likely, 10,000 training examples are just too few to saturate a model of this many parameters, and/or it is possible the setup was somehow ill-posed. This may become more apparent with a run over the full data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
